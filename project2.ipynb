{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Utility methods\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# do PCA to reduce dimensionality, required for RVM and GPR\n",
    "def reduce_dimensions(data):\n",
    "    pca = decomposition.PCA(n_components = 7)\n",
    "    \n",
    "    X = pca.fit_transform(data)\n",
    "    return X\n",
    "\n",
    "# reads model from pickled object file\n",
    "def readObj(name):\n",
    "    with open(name, 'rb') as input:\n",
    "        clf = pickle.load(input)\n",
    "    \n",
    "    return clf\n",
    "\n",
    "# writes model to a pickled object file\n",
    "def writeObj(name, obj):\n",
    "    with open(name, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "loading input - output data and explore the dataset\n",
    "\n",
    "'''\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from sklearn import decomposition\n",
    "\n",
    "inputDataPath  = 'data/Proj2FeatVecsSet1.mat'\n",
    "outputDataPath = 'data/Proj2TargetOutputsSet1.mat'\n",
    "\n",
    "inputDataObj  = loadmat(inputDataPath)\n",
    "outputDataObj = loadmat(outputDataPath)\n",
    "\n",
    "inputData  = inputDataObj['Proj2FeatVecsSet1']\n",
    "outputData = outputDataObj['Proj2TargetOutputsSet1']\n",
    "\n",
    "\n",
    "data = zip(inputData, outputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "pretty prints confusion matrix and returns confusion matrix and accuracy score\n",
    "\n",
    "@param   Y                   predicted labels\n",
    "\n",
    "@param   ClassLabels         actual / true labels\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "def MyConfusionMatrix(Y, ClassNames):\n",
    "    ClassLabels = list(np.unique(ClassNames))\n",
    "    \n",
    "    conf_matrix = confusion_matrix(Y, ClassNames)\n",
    "    accuracy = accuracy_score(Y, ClassNames)\n",
    "    \n",
    "    columns = tuple(ClassLabels)\n",
    "    rows = tuple(ClassLabels)\n",
    "    \n",
    "    df = pd.DataFrame(data=conf_matrix, columns=ClassLabels)\n",
    "    \n",
    "    print \"\\nconfusion matrix: \\n\"\n",
    "    print df\n",
    "    \n",
    "    return conf_matrix, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SVM (Support Vector Machine):\n",
    "\n",
    "performs grid search to compute optimal hyper-parameters\n",
    "uses those hyper-parameters for the estimator, fits it on the training data\n",
    "\n",
    "returns trained model and writes it to file for transfer learning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def SVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train):\n",
    "\n",
    "    hyper_param_grid = [\n",
    "        {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}\n",
    "    ]\n",
    "\n",
    "    estimator = GridSearchCV(SVC(decision_function_shape='ovr'), hyper_param_grid, cv=3, scoring='precision_macro')\n",
    "    \n",
    "    print \"SVM: executing grid search to find optimal hyper-parameters\"\n",
    "    \n",
    "    estimator.fit(X_hyper, Y_hyper)\n",
    "\n",
    "    clf = estimator.best_estimator_\n",
    "    \n",
    "    print \"found best hyperparameters:\"\n",
    "\n",
    "    print estimator.best_params_\n",
    "    print \"training the estimator\"\n",
    "\n",
    "    if train:\n",
    "        clf.fit(X_train, Y_train)\n",
    "        writeObj('svm_model.pkl', clf)\n",
    "        \n",
    "        Y_pred = clf.predict(X_validate)\n",
    "        return Y_pred, clf\n",
    "    \n",
    "    else:\n",
    "        clf = readObj('svm_model.pkl')\n",
    "        print clf.score(X_validate, Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RVM (Relevance Vector Machine):\n",
    "\n",
    "uses PCA to reduce dimensionality as RVM training takes a long time\n",
    "also uses a subset of training data to save time\n",
    "\n",
    "\n",
    "returns trained model and writes it to file for transfer learning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def RVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train):\n",
    "    clf = OneVsRestClassifier(RVC(n_iter=1))\n",
    "    start = time.clock()\n",
    "    \n",
    "    X_train_reduced = reduce_dimensions(X_train)\n",
    "    X_validate_reduced = reduce_dimensions(X_validate)\n",
    "    \n",
    "    if train:\n",
    "        clf.fit(X_train_reduced[:200, :], Y_train[:200])\n",
    "        writeObj('rvm_model.pkl', clf)\n",
    "        \n",
    "        Y_pred = clf.predict(X_validate)\n",
    "        return Y_pred, clf\n",
    "    else:\n",
    "        clf = readObj('rvm_model.pkl')\n",
    "        print clf.score(X_validate_reduced, Y_validate)\n",
    "\n",
    "    print \"training took \", time.clock() - start, \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GPR (Gaussian Process Regressor):\n",
    "\n",
    "uses PCA to reduce dimensionality as training takes a long time\n",
    "also uses a subset of training data to save time\n",
    "\n",
    "returns trained model and writes it to file for transfer learning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import pickle\n",
    "\n",
    "def GPR(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train):\n",
    "    print \"GPR training :\"\n",
    "    \n",
    "    X_train_reduced = reduce_dimensions(X_train)\n",
    "    X_validate_reduced = reduce_dimensions(X_validate)\n",
    "    \n",
    "    if train:\n",
    "        start = time.clock()\n",
    "        kernel_rbf = 1.0 * RBF()\n",
    "        \n",
    "        clf = GaussianProcessClassifier(kernel=kernel_rbf, multi_class='one_vs_rest')\n",
    "        clf.fit(X_train_reduced[:500, :], Y_train[:500])\n",
    "\n",
    "        writeObj('gaussian_model.pkl', clf)\n",
    "        print \"training took \", time.clock() - start, \" s\"\n",
    "        \n",
    "        Y_pred = clf.predict(X_validate_reduced)\n",
    "        return Y_pred, clf\n",
    "    else:\n",
    "        clf = readObj('gaussian_model.pkl')\n",
    "\n",
    "        print clf.score(X_validate_reduced[:500, :], Y_validate[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from skrvm import RVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def MyTrainClassifier(XEstimate, XValidate, Parameters):\n",
    "    \n",
    "    X_train, Y_train = zip(*XEstimate)\n",
    "\n",
    "    X_train = np.array(list(X_train))\n",
    "    Y_train = np.array([np.where(output == 1)[0][0] for output in list(Y_train)])\n",
    "\n",
    "    # sampling a small amount of training data for finding optimal hyper-parameters\n",
    "    X_hyper = X_train[:500, :]\n",
    "    Y_hyper = Y_train[:500]\n",
    "\n",
    "    X_validate, Y_validate = zip(*XValidate)\n",
    "\n",
    "    X_validate = np.array(list(X_validate))\n",
    "    Y_validate = np.array([np.where(output == 1)[0][0] for output in list(Y_validate)])\n",
    "    \n",
    "    train = Parameters['training_mode']\n",
    "    \n",
    "    # SVM\n",
    "    if Parameters['algorithm'] == 'SVM':\n",
    "\n",
    "        Y_predict, model = SVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train)\n",
    "\n",
    "    elif Parameters['algorithm'] == 'RVM':\n",
    "\n",
    "        Y_predict, model = RVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train)\n",
    "\n",
    "    elif Parameters['algorithm'] == 'GPR':\n",
    "\n",
    "        Y_predict, model = GPR(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train)\n",
    "\n",
    "    return Y_predict, {'model' : model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "takes in XTest ( which is a zipped form of input and output data tuples ) and a trained model\n",
    "evaluates the performance of the model\n",
    "\n",
    "\"\"\"\n",
    "def TestMyClassifier(XTest, EstParameters):\n",
    "    model = EstParameters['model']\n",
    "    \n",
    "    X, Y = zip(*XTest)\n",
    "    \n",
    "    Xactual = np.array(list(X))\n",
    "    Yactual = np.array([np.where(output == 1)[0][0] for output in list(Y)])\n",
    "    Ypred = []\n",
    "    \n",
    "    for x in X:\n",
    "        p = model.predict_proba(X)\n",
    "        y = p.index(max(p))\n",
    "        \n",
    "        Ypred.append(y)\n",
    "        \n",
    "    return Ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "performs K-fold cross validation and selects the best model to prevent overfitting\n",
    "returns the array of confusion matrices and estimated parameter models for every fold\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.model_selection import KFold\n",
    "from random import shuffle\n",
    "\n",
    "def MyCrossValidate(XTrain, Nf):\n",
    "    shuffle(XTrain)\n",
    "    kf = KFold(n_splits = Nf)\n",
    "    \n",
    "    j = 1\n",
    "    \n",
    "    EstParameters = []\n",
    "    EstConfMatrices = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(XTrain):\n",
    "        En = [XTrain[i] for i in train_index]\n",
    "        Vn = [XTrain[i] for i in test_index]\n",
    "        \n",
    "        print \"\\nfold {} in progress:\\n\".format(j)\n",
    "        \n",
    "        Y_predicted, EstParameter = MyTrainClassifier(En, Vn, {'algorithm':'SVM', 'training_mode':True})\n",
    "        \n",
    "        _, Y_validate = zip(*Vn)\n",
    "        Y_validate = np.array([np.where(output == 1)[0][0] for output in list(Y_validate)])\n",
    "        \n",
    "        Cn, acc = MyConfusionMatrix(Y_predicted, Y_validate)\n",
    "        \n",
    "        EstConfMatrices.append(Cn)\n",
    "        EstParameters.append(EstParameter)\n",
    "        \n",
    "        accuracies.append(acc)\n",
    "        \n",
    "        j = j + 1\n",
    "    \n",
    "    print \"\"\n",
    "    \n",
    "    best_model_idx = accuracies.index(max(accuracies))\n",
    "    best_model = EstParameters[best_model_idx]['model']\n",
    "    \n",
    "    X, Y = zip(*XTrain)\n",
    "    \n",
    "    X = np.array(list(X))\n",
    "    Y = np.array([np.where(output == 1)[0][0] for output in list(Y)])\n",
    "    \n",
    "    YTrain = best_model.predict(X)\n",
    "    \n",
    "    print \"overall confusion matrix :\"\n",
    "    \n",
    "    ConfMatrix, acc = MyConfusionMatrix(YTrain, Y)\n",
    "    \n",
    "    return YTrain, EstParameters, EstConfMatrices, ConfMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fold 1 in progress:\n",
      "\n",
      "SVM: executing grid search to find optimal hyper-parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/humble_learner/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found best hyperparameters:\n",
      "{'kernel': 'linear', 'C': 100}\n",
      "training the estimator\n",
      "\n",
      "confusion matrix: \n",
      "\n",
      "      0    1    2     3     4\n",
      "0  1001    3    5     0     3\n",
      "1     2  928    2    16     1\n",
      "2     5    1  985     1     1\n",
      "3     0   17    2  1008     3\n",
      "4     0    2    4    10  1000\n",
      "\n",
      "fold 2 in progress:\n",
      "\n",
      "SVM: executing grid search to find optimal hyper-parameters\n",
      "found best hyperparameters:\n",
      "{'kernel': 'linear', 'C': 10}\n",
      "training the estimator\n",
      "\n",
      "confusion matrix: \n",
      "\n",
      "     0    1    2    3    4\n",
      "0  969    2    6    2    1\n",
      "1    3  998    1   15    0\n",
      "2    3    1  963    2    7\n",
      "3    0   35    1  957   10\n",
      "4    0    0   15   11  998\n",
      "\n",
      "fold 3 in progress:\n",
      "\n",
      "SVM: executing grid search to find optimal hyper-parameters\n",
      "found best hyperparameters:\n",
      "{'kernel': 'linear', 'C': 10}\n",
      "training the estimator\n",
      "\n",
      "confusion matrix: \n",
      "\n",
      "      0    1     2    3     4\n",
      "0  1011    3     7    1     3\n",
      "1     2  948     1   21     0\n",
      "2     4    4  1018    3     7\n",
      "3     0   17     0  921     5\n",
      "4     3    0     5    5  1011\n",
      "\n",
      "fold 4 in progress:\n",
      "\n",
      "SVM: executing grid search to find optimal hyper-parameters\n",
      "found best hyperparameters:\n",
      "{'kernel': 'linear', 'C': 10}\n",
      "training the estimator\n",
      "\n",
      "confusion matrix: \n",
      "\n",
      "     0    1    2    3    4\n",
      "0  999    4    6    2    1\n",
      "1    3  973    0   27    0\n",
      "2    3    1  993    3    4\n",
      "3    0   16    1  980    2\n",
      "4    1    1    9    9  962\n",
      "\n",
      "fold 5 in progress:\n",
      "\n",
      "SVM: executing grid search to find optimal hyper-parameters\n",
      "found best hyperparameters:\n",
      "{'kernel': 'linear', 'C': 10}\n",
      "training the estimator\n",
      "\n",
      "confusion matrix: \n",
      "\n",
      "     0     1    2    3    4\n",
      "0  985     3    5   10    3\n",
      "1    2  1030    1   19    0\n",
      "2    4     2  961    3    8\n",
      "3    0    11    3  971    8\n",
      "4    0     0    6    3  962\n",
      "\n",
      "overall confusion matrix :\n",
      "\n",
      "confusion matrix: \n",
      "\n",
      "      0     1     2     3     4\n",
      "0  4978     8    21     9     8\n",
      "1     7  4897     8    81     2\n",
      "2    14     4  4938     9    21\n",
      "3     0    89     6  4871    18\n",
      "4     1     2    27    30  4951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2, 4, 3, ..., 4, 0, 3]),\n",
       " [{'model': SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False)},\n",
       "  {'model': SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False)},\n",
       "  {'model': SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False)},\n",
       "  {'model': SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False)},\n",
       "  {'model': SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False)}],\n",
       " [array([[1001,    3,    5,    0,    3],\n",
       "         [   2,  928,    2,   16,    1],\n",
       "         [   5,    1,  985,    1,    1],\n",
       "         [   0,   17,    2, 1008,    3],\n",
       "         [   0,    2,    4,   10, 1000]]), array([[969,   2,   6,   2,   1],\n",
       "         [  3, 998,   1,  15,   0],\n",
       "         [  3,   1, 963,   2,   7],\n",
       "         [  0,  35,   1, 957,  10],\n",
       "         [  0,   0,  15,  11, 998]]), array([[1011,    3,    7,    1,    3],\n",
       "         [   2,  948,    1,   21,    0],\n",
       "         [   4,    4, 1018,    3,    7],\n",
       "         [   0,   17,    0,  921,    5],\n",
       "         [   3,    0,    5,    5, 1011]]), array([[999,   4,   6,   2,   1],\n",
       "         [  3, 973,   0,  27,   0],\n",
       "         [  3,   1, 993,   3,   4],\n",
       "         [  0,  16,   1, 980,   2],\n",
       "         [  1,   1,   9,   9, 962]]), array([[ 985,    3,    5,   10,    3],\n",
       "         [   2, 1030,    1,   19,    0],\n",
       "         [   4,    2,  961,    3,    8],\n",
       "         [   0,   11,    3,  971,    8],\n",
       "         [   0,    0,    6,    3,  962]])],\n",
       " array([[4978,    8,   21,    9,    8],\n",
       "        [   7, 4897,    8,   81,    2],\n",
       "        [  14,    4, 4938,    9,   21],\n",
       "        [   0,   89,    6, 4871,   18],\n",
       "        [   1,    2,   27,   30, 4951]]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyCrossValidate(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
