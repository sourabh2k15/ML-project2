{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load input - output data and understand the structure\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "inputDataPath  = 'data/Proj2FeatVecsSet1.mat'\n",
    "outputDataPath = 'data/Proj2TargetOutputsSet1.mat'\n",
    "\n",
    "inputDataObj  = loadmat(inputDataPath)\n",
    "outputDataObj = loadmat(outputDataPath)\n",
    "\n",
    "inputData  = inputDataObj['Proj2FeatVecsSet1']\n",
    "outputData = outputDataObj['Proj2TargetOutputsSet1']\n",
    "\n",
    "data = zip(inputData, outputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "computes confusion matrix\n",
    "\n",
    "@param   Y                   predicted labels\n",
    "\n",
    "@param   ClassLabels         actual / true labels  \n",
    "\n",
    "\"\"\" \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def MyConfusionMatrix(Y, ClassNames):\n",
    "    return confusion_matrix(Y, ClassNames)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "training script\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from skrvm import RVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def MyTrainClassifier(XEstimate, XValidate, Parameters):\n",
    "    \n",
    "    X_train, Y_train = zip(*XEstimate)\n",
    "        \n",
    "    X_train = np.array(list(X_train))\n",
    "    Y_train = np.array([np.where(output == 1)[0][0] for output in list(Y_train)])\n",
    "    \n",
    "    # sampling a small amount of training data for finding optimal hyper-parameters\n",
    "    X_hyper = X_train[:1000, :]\n",
    "    Y_hyper = Y_train[:1000]\n",
    "    \n",
    "    X_validate, Y_validate = zip(*XValidate)\n",
    "        \n",
    "    X_validate = list(X_validate)\n",
    "    Y_validate = [np.where(output == 1)[0][0] for output in list(Y_validate)]\n",
    "    \n",
    "    # SVM\n",
    "    # all vs all pair training\n",
    "    if Parameters['algorithm'] == 'SVM':\n",
    "        \n",
    "        SVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate)\n",
    "    \n",
    "    elif Parameters['algorithm'] == 'RVM':\n",
    "        \n",
    "        RVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate)        \n",
    "    \n",
    "    elif Parameters['algorithm'] == 'Gaussian':\n",
    "     \n",
    "        Gaussian(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate):\n",
    "    \n",
    "    hyper_param_grid = [\n",
    "        {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}\n",
    "    ]\n",
    "\n",
    "    estimator = GridSearchCV(SVC(decision_function_shape='ovo'), hyper_param_grid, cv=3, scoring='precision_macro')    \n",
    "    estimator.fit(X_hyper, Y_hyper) \n",
    "    \n",
    "    clf = estimator.best_estimator_\n",
    "    print \"found best estimator, training the estimator\"\n",
    "    \n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    print \"completed training\"\n",
    "    \n",
    "    print clf.score(X_validate, Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate):\n",
    "    clf = RVC(n_iter=1, kernel='linear')\n",
    "\n",
    "    start = time.clock()\n",
    "\n",
    "    clf.fit(X_hyper, Y_hyper)\n",
    "    print time.clock() - start, \"s\"\n",
    "\n",
    "    print clf.score(X_validate, Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "    \n",
    "def Gaussian(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate):\n",
    "    print \"gaussian in progress\"\n",
    "    \n",
    "    kernel = 1.0 * RBF([1.0, 1.0])\n",
    "    clf = GaussianProcessClassifier(kernel, multi_class='one_vs_one')\n",
    "\n",
    "    myclf = OVO('gaussian')\n",
    "    myclf.fit(X_hyper, Y_hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    " K-fold cross validation script\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.model_selection import KFold\n",
    "from random import shuffle\n",
    "\n",
    "def MyCrossValidate(XTrain, Nf):\n",
    "    shuffle(XTrain)\n",
    "    kf = KFold(n_splits = Nf)\n",
    "    \n",
    "    j = 1\n",
    "    \n",
    "    for train_index, test_index in kf.split(XTrain):\n",
    "        En = [XTrain[i] for i in train_index]\n",
    "        Vn = [XTrain[i] for i in test_index]\n",
    "        \n",
    "        print \"fold {} in progress\".format(j)\n",
    "        \n",
    "        MyTrainClassifier(En, Vn, {'algorithm':'Gaussian'})\n",
    "        \n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OVO:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def fact(self, n):\n",
    "        if n == 0:\n",
    "            return 1\n",
    "        \n",
    "        return n*self.fact(n-1)\n",
    "\n",
    "    def nCr(self, n, r):\n",
    "        return self.fact(n)/(self.fact(n-r)*self.fact(r))\n",
    "    \n",
    "    def getModel(self):\n",
    "        if self.model == 'gaussian':\n",
    "            return GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=1.0))\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        Nclasses     = len(np.unique(Y))\n",
    "        Nclassifiers = self.nCr(Nclasses, 2)\n",
    "        \n",
    "        dataparts = [None]*Nclasses\n",
    "        classifiers = []\n",
    "        \n",
    "        for i in range(Nclasses):\n",
    "            dataparts[i] = np.where(Y == i)[0]\n",
    "            \n",
    "        for i in range(Nclasses):\n",
    "            for j in range(i+1, Nclasses):\n",
    "                \"training classifier: \", i, \" \",j\n",
    "                \n",
    "                xi = X[dataparts[i]]\n",
    "                xj = X[dataparts[j]]\n",
    "                \n",
    "                yi = [0]*len(xi)\n",
    "                yj = [1]*len(xj)\n",
    "                \n",
    "                x = np.vstack([xi, xj])\n",
    "                y = np.hstack([yi, yj])\n",
    "                \n",
    "                clf = self.getModel() \n",
    "                clf.fit(x, y)\n",
    "                \n",
    "                classifiers.append((i, j, clf))\n",
    "        \n",
    "        print classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 in progress\n",
      "gaussian in progress\n"
     ]
    }
   ],
   "source": [
    "MyCrossValidate(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.675773 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Marginal Likelihood (initial): -17.598\n",
      "Log Marginal Likelihood (optimized): -3.875\n",
      "Accuracy: 1.000 (initial) 1.000 (optimized)\n",
      "Log-loss: 0.214 (initial) 0.319 (optimized)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "\n",
    "# Generate data\n",
    "train_size = 50\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "X = rng.uniform(0, 5, 100)[:, np.newaxis]\n",
    "y = np.array(X[:, 0] > 2.5, dtype=int)\n",
    "\n",
    "gp_fix = GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=1.0),\n",
    "                                   optimizer=None)\n",
    "gp_fix.fit(X[:train_size], y[:train_size])\n",
    "\n",
    "gp_opt = GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=1.0))\n",
    "gp_opt.fit(X[:train_size], y[:train_size])\n",
    "\n",
    "print \"Log Marginal Likelihood (initial): %.3f\" % gp_fix.log_marginal_likelihood(gp_fix.kernel_.theta)\n",
    "print \"Log Marginal Likelihood (optimized): %.3f\"% gp_opt.log_marginal_likelihood(gp_opt.kernel_.theta)\n",
    "\n",
    "print \"Accuracy: %.3f (initial) %.3f (optimized)\"% (accuracy_score(y[:train_size], gp_fix.predict(X[:train_size])),\n",
    "         accuracy_score(y[:train_size], gp_opt.predict(X[:train_size])))\n",
    "print \"Log-loss: %.3f (initial) %.3f (optimized)\" % (log_loss(y[:train_size], gp_fix.predict_proba(X[:train_size])[:, 1]),\n",
    "         log_loss(y[:train_size], gp_opt.predict_proba(X[:train_size])[:, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "yi = [0]*5\n",
    "yj = [1]*10\n",
    "\n",
    "print yi\n",
    "print yj\n",
    "\n",
    "print np.hstack([yi, yj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
