{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "loading input - output data and explore the dataset\n",
    "\n",
    "'''\n",
    "from scipy.io import loadmat\n",
    "\n",
    "inputDataPath  = 'data/Proj2FeatVecsSet1.mat'\n",
    "outputDataPath = 'data/Proj2TargetOutputsSet1.mat'\n",
    "\n",
    "inputDataObj  = loadmat(inputDataPath)\n",
    "outputDataObj = loadmat(outputDataPath)\n",
    "\n",
    "inputData  = inputDataObj['Proj2FeatVecsSet1']\n",
    "outputData = outputDataObj['Proj2TargetOutputsSet1']\n",
    "\n",
    "data = zip(inputData, outputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "computes confusion matrix\n",
    "\n",
    "@param   Y                   predicted labels\n",
    "\n",
    "@param   ClassLabels         actual / true labels  \n",
    "\n",
    "\"\"\" \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def MyConfusionMatrix(Y, ClassNames):\n",
    "    return confusion_matrix(Y, ClassNames)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "training script\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from skrvm import RVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def MyTrainClassifier(XEstimate, XValidate, Parameters):\n",
    "    \n",
    "    X_train, Y_train = zip(*XEstimate)\n",
    "        \n",
    "    X_train = np.array(list(X_train))\n",
    "    Y_train = np.array([np.where(output == 1)[0][0] for output in list(Y_train)])\n",
    "    \n",
    "    # sampling a small amount of training data for finding optimal hyper-parameters\n",
    "    X_hyper = X_train[:500, :]\n",
    "    Y_hyper = Y_train[:500]\n",
    "    \n",
    "    X_validate, Y_validate = zip(*XValidate)\n",
    "        \n",
    "    X_validate = np.array(list(X_validate))\n",
    "    Y_validate = np.array([np.where(output == 1)[0][0] for output in list(Y_validate)])\n",
    "    \n",
    "    # SVM\n",
    "    # all vs all pair training\n",
    "    if Parameters['algorithm'] == 'SVM':\n",
    "        \n",
    "        SVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, False)\n",
    "    \n",
    "    elif Parameters['algorithm'] == 'RVM':\n",
    "        \n",
    "        RVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate)        \n",
    "    \n",
    "    elif Parameters['algorithm'] == 'Gaussian':\n",
    "     \n",
    "        Gaussian(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train):\n",
    "    \n",
    "    hyper_param_grid = [\n",
    "        {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}\n",
    "    ]\n",
    "\n",
    "    estimator = GridSearchCV(SVC(decision_function_shape='ovo'), hyper_param_grid, cv=3, scoring='precision_macro')    \n",
    "    estimator.fit(X_hyper, Y_hyper) \n",
    "    \n",
    "    clf = estimator.best_estimator_\n",
    "    print \"found best estimator, training the estimator\"\n",
    "    \n",
    "    if train:\n",
    "        clf.fit(X_train, Y_train)\n",
    "        writeObj('svm_model.pkl', clf)\n",
    "    else:\n",
    "        clf = readObj('svm_model.pkl')\n",
    "        print clf.score(X_validate, Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate):\n",
    "    clf = RVC(n_iter=1, kernel='linear')\n",
    "\n",
    "    start = time.clock()\n",
    "\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    writeObj('rvm_model.pkl', clf)\n",
    "    \n",
    "    print time.clock() - start, \"s\"\n",
    "    print clf.score(X_validate, Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import pickle\n",
    "\n",
    "def Gaussian(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train):\n",
    "    print \"gaussian in progress\"\n",
    "        \n",
    "    if train:\n",
    "        kernel_rbf = 1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-5, 100000.0))\n",
    "    \n",
    "        clf = GaussianProcessClassifier(kernel=kernel_rbf, multi_class='one_vs_rest')\n",
    "        clf.fit(X_hyper, Y_hyper)\n",
    "\n",
    "        writeObj('gaussian_model', clf)\n",
    "    else:\n",
    "        clf = readObj('gaussian_model')\n",
    "        \n",
    "        print clf.score(X_validate[:500, :], Y_validate[:500])\n",
    "    #print clf.predict_proba([X_validate[0]])\n",
    "    \n",
    "    #myclf = OVO('gaussian')\n",
    "    #myclf.fit(X_train, Y_train)\n",
    "    \n",
    "    #print myclf.predict(X_validate[:500, :])\n",
    "    #print Y_validate[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeObj(name, obj):\n",
    "    with open(name, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readObj(name):\n",
    "    with open(name, 'rb') as input:\n",
    "        clf = pickle.load(input)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    " K-fold cross validation script\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.model_selection import KFold\n",
    "from random import shuffle\n",
    "\n",
    "def MyCrossValidate(XTrain, Nf):\n",
    "    shuffle(XTrain)\n",
    "    kf = KFold(n_splits = Nf)\n",
    "    \n",
    "    j = 1\n",
    "    \n",
    "    for train_index, test_index in kf.split(XTrain):\n",
    "        En = [XTrain[i] for i in train_index]\n",
    "        Vn = [XTrain[i] for i in test_index]\n",
    "        \n",
    "        print \"fold {} in progress\".format(j)\n",
    "        \n",
    "        MyTrainClassifier(En, Vn, {'algorithm':'SVM'})\n",
    "        \n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 in progress\n",
      "found best estimator, training the estimator\n",
      "0.9866\n",
      "fold 2 in progress\n",
      "found best estimator, training the estimator\n",
      "0.9832\n",
      "fold 3 in progress\n",
      "found best estimator, training the estimator\n",
      "0.9858\n",
      "fold 4 in progress\n",
      "found best estimator, training the estimator\n",
      "0.9856\n",
      "fold 5 in progress\n",
      "found best estimator, training the estimator\n",
      "0.9882\n"
     ]
    }
   ],
   "source": [
    "MyCrossValidate(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OVO:\n",
    "    def __init__(self, model):\n",
    "        self.model_ = model\n",
    "        \n",
    "    def fact(self, n):\n",
    "        if n == 0:\n",
    "            return 1\n",
    "        \n",
    "        return n*self.fact(n-1)\n",
    "\n",
    "    def nCr(self, n, r):\n",
    "        return self.fact(n)/(self.fact(n-r)*self.fact(r))\n",
    "    \n",
    "    def getModel(self):\n",
    "        if self.model_ == 'gaussian':\n",
    "            return GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=1.0))\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        self.Nclasses_     = len(np.unique(Y))\n",
    "        self.Nclassifiers_ = self.nCr(self.Nclasses_, 2)\n",
    "        \n",
    "        Nclasses = self.Nclasses_\n",
    "        Nclassifiers = self.Nclassifiers_\n",
    "        \n",
    "        dataparts = [None]*Nclasses\n",
    "        classifiers = [[None]*Nclasses]*Nclasses\n",
    "        \n",
    "        print classifiers\n",
    "        \n",
    "        for i in range(Nclasses):\n",
    "            dataparts[i] = np.where(Y == i)[0]\n",
    "            \n",
    "        for i in range(Nclasses):\n",
    "            for j in range(i+1, Nclasses):\n",
    "                print \"training classifier: \", i, \" \",j\n",
    "                \n",
    "                xi = X[dataparts[i]]\n",
    "                xj = X[dataparts[j]]\n",
    "                \n",
    "                yi = [0]*len(xi)\n",
    "                yj = [1]*len(xj)\n",
    "                \n",
    "                x = np.vstack([xi, xj])\n",
    "                y = np.hstack([yi, yj])\n",
    "                \n",
    "                clf = self.getModel() \n",
    "                \n",
    "                print \"clf fitting\"\n",
    "                clf.fit(x, y)\n",
    "                print \"clf fitting done\"\n",
    "                \n",
    "                classifiers[i][j] = clf\n",
    "        \n",
    "        self.classifiers = classifiers\n",
    "        #print classifiers\n",
    "    \n",
    "    def predict(self, X):\n",
    "        Nclasses = self.Nclasses_\n",
    "        Nclassifiers = self.Nclassifiers_\n",
    "        \n",
    "        classifiers = self.classifiers\n",
    "        \n",
    "        Y = []\n",
    "        \n",
    "        for x in X:\n",
    "            probabilities = [0]*Nclasses\n",
    "\n",
    "            for i in range(Nclasses):\n",
    "                for j in range(i+1, Nclasses):\n",
    "                    clf = classifiers[i][j]\n",
    "                \n",
    "                    probabilities[i] += clf.predict_proba(X)[0][0]\n",
    "                    probabilities[j] += clf.predict_proba(X)[0][1]\n",
    "                \n",
    "            Y.append(probabilities.index(max(probabilities)))\n",
    "        \n",
    "        return Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
