{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "loading input - output data and explore the dataset\n",
    "\n",
    "'''\n",
    "from scipy.io import loadmat\n",
    "from sklearn import decomposition\n",
    "\n",
    "inputDataPath  = 'data/Proj2FeatVecsSet1.mat'\n",
    "outputDataPath = 'data/Proj2TargetOutputsSet1.mat'\n",
    "\n",
    "inputDataObj  = loadmat(inputDataPath)\n",
    "outputDataObj = loadmat(outputDataPath)\n",
    "\n",
    "inputData  = inputDataObj['Proj2FeatVecsSet1']\n",
    "outputData = outputDataObj['Proj2TargetOutputsSet1']\n",
    "\n",
    "\n",
    "data = zip(inputData, outputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "computes confusion matrix\n",
    "\n",
    "@param   Y                   predicted labels\n",
    "\n",
    "@param   ClassLabels         actual / true labels\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "def MyConfusionMatrix(Y, ClassNames):\n",
    "    ClassLabels = list(np.unique(ClassNames))\n",
    "    \n",
    "    conf_matrix = confusion_matrix(Y, ClassNames)\n",
    "    accuracy = accuracy_score(Y, ClassNames)\n",
    "    \n",
    "    columns = tuple(ClassLabels)\n",
    "    rows = tuple(ClassLabels)\n",
    "    \n",
    "    df = pd.DataFrame(data=conf_matrix, columns=ClassLabels)\n",
    "    \n",
    "    print \"\\nconfusion matrix: \\n\"\n",
    "    print df\n",
    "    \n",
    "    return conf_matrix, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train):\n",
    "\n",
    "    hyper_param_grid = [\n",
    "        {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}\n",
    "    ]\n",
    "\n",
    "    estimator = GridSearchCV(SVC(decision_function_shape='ovr'), hyper_param_grid, cv=3, scoring='precision_macro')\n",
    "    \n",
    "    print \"SVM: executing grid search to find optimal hyper-parameters\"\n",
    "    \n",
    "    estimator.fit(X_hyper, Y_hyper)\n",
    "\n",
    "    clf = estimator.best_estimator_\n",
    "    \n",
    "    print \"found best hyperparameters:\"\n",
    "    print estimator.best_params_\n",
    "    print \"training the estimator\"\n",
    "\n",
    "    if train:\n",
    "        clf.fit(X_train, Y_train)\n",
    "        writeObj('svm_model.pkl', clf)\n",
    "        \n",
    "        Y_pred = clf.predict(X_validate)\n",
    "        return Y_pred, clf\n",
    "    \n",
    "    else:\n",
    "        clf = readObj('svm_model.pkl')\n",
    "        print clf.score(X_validate, Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train):\n",
    "    clf = OneVsRestClassifier(RVC(n_iter=1))\n",
    "    start = time.clock()\n",
    "    \n",
    "    X_train_reduced = reduce_dimensions(X_train)\n",
    "    X_validate_reduced = reduce_dimensions(X_validate)\n",
    "    \n",
    "    if train:\n",
    "        clf.fit(X_train_reduced[:5000, :], Y_train[:5000])\n",
    "        writeObj('rvm_model.pkl', clf)\n",
    "    else:\n",
    "        clf = readObj('rvm_model.pkl')\n",
    "        print clf.score(X_validate_reduced, Y_validate)\n",
    "\n",
    "    print time.clock() - start, \"s\"\n",
    "    print clf.predict_proba(X_validate[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import pickle\n",
    "\n",
    "def Gaussian(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train):\n",
    "    print \"GPR:\"\n",
    "    \n",
    "    X_train_reduced = reduce_dimensions(X_train)\n",
    "    X_validate_reduced = reduce_dimensions(X_validate)\n",
    "    \n",
    "    if train:\n",
    "        kernel_rbf = 1.0 * RBF()\n",
    "\n",
    "        clf = GaussianProcessClassifier(kernel=kernel_rbf, multi_class='one_vs_rest')\n",
    "        clf.fit(X_train_reduced[:1000, :], Y_train[:1000])\n",
    "\n",
    "        writeObj('gaussian_model', clf)\n",
    "    else:\n",
    "        clf = readObj('gaussian_model')\n",
    "\n",
    "        print clf.score(X_validate_reduced[:500, :], Y_validate[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from skrvm import RVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def MyTrainClassifier(XEstimate, XValidate, Parameters):\n",
    "    \n",
    "    X_train, Y_train = zip(*XEstimate)\n",
    "\n",
    "    X_train = np.array(list(X_train))\n",
    "    Y_train = np.array([np.where(output == 1)[0][0] for output in list(Y_train)])\n",
    "\n",
    "    # sampling a small amount of training data for finding optimal hyper-parameters\n",
    "    X_hyper = X_train[:500, :]\n",
    "    Y_hyper = Y_train[:500]\n",
    "\n",
    "    X_validate, Y_validate = zip(*XValidate)\n",
    "\n",
    "    X_validate = np.array(list(X_validate))\n",
    "    Y_validate = np.array([np.where(output == 1)[0][0] for output in list(Y_validate)])\n",
    "    \n",
    "    train = Parameters['training_mode']\n",
    "    \n",
    "    # SVM\n",
    "    if Parameters['algorithm'] == 'SVM':\n",
    "\n",
    "        Y_predict, model = SVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train)\n",
    "\n",
    "    elif Parameters['algorithm'] == 'RVM':\n",
    "\n",
    "        Y_predict, model = RVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train)\n",
    "\n",
    "    elif Parameters['algorithm'] == 'GPR':\n",
    "\n",
    "        Y_predict, model = Gaussian(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train)\n",
    "\n",
    "    return Y_predict, {'model' : model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    " K-fold cross validation script\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.model_selection import KFold\n",
    "from random import shuffle\n",
    "\n",
    "def MyCrossValidate(XTrain, Nf):\n",
    "    shuffle(XTrain)\n",
    "    kf = KFold(n_splits = Nf)\n",
    "    \n",
    "    j = 1\n",
    "    \n",
    "    EstParameters = []\n",
    "    EstConfMatrices = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(XTrain):\n",
    "        En = [XTrain[i] for i in train_index]\n",
    "        Vn = [XTrain[i] for i in test_index]\n",
    "        \n",
    "        print \"\\nfold {} in progress:\\n\".format(j)\n",
    "        \n",
    "        Y_predicted, EstParameter = MyTrainClassifier(En, Vn, {'algorithm':'GPR', 'training_mode':True})\n",
    "        \n",
    "        _, Y_validate = zip(*Vn)\n",
    "        Y_validate = np.array([np.where(output == 1)[0][0] for output in list(Y_validate)])\n",
    "        \n",
    "        Cn, acc = MyConfusionMatrix(Y_predicted, Y_validate)\n",
    "        \n",
    "        EstConfMatrices.append(Cn)\n",
    "        EstParameters.append(EstParameter)\n",
    "        \n",
    "        accuracies.append(acc)\n",
    "        \n",
    "        j = j + 1\n",
    "    \n",
    "    print \"\"\n",
    "    \n",
    "    best_model_idx = accuracies.index(max(accuracies))\n",
    "    best_model = EstParameters[best_model_idx]['model']\n",
    "    \n",
    "    X, Y = zip(*XTrain)\n",
    "    \n",
    "    X = np.array(list(X))\n",
    "    Y = np.array([np.where(output == 1)[0][0] for output in list(Y)])\n",
    "    \n",
    "    YTrain = best_model.predict(X)\n",
    "    \n",
    "    print \"overall confusion matrix :\"\n",
    "    \n",
    "    ConfMatrix, acc = MyConfusionMatrix(YTrain, Y)\n",
    "    \n",
    "    return YTrain, EstParameters, EstConfMatrices, ConfMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fold 1 in progress:\n",
      "\n",
      "GPR:\n"
     ]
    }
   ],
   "source": [
    "MyCrossValidate(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeObj(name, obj):\n",
    "    with open(name, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readObj(name):\n",
    "    with open(name, 'rb') as input:\n",
    "        clf = pickle.load(input)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_dimensions(data):\n",
    "    pca = decomposition.PCA(n_components = 7)\n",
    "    \n",
    "    X = pca.fit_transform(data)\n",
    "    return X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
