{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Utility methods\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# do PCA to reduce dimensionality, required for RVM and GPR\n",
    "def reduce_dimensions(data):\n",
    "    pca = decomposition.PCA(n_components = 7)\n",
    "    \n",
    "    X = pca.fit_transform(data)\n",
    "    return X\n",
    "\n",
    "# reads model from pickled object file\n",
    "def readObj(name):\n",
    "    with open(name, 'rb') as input:\n",
    "        clf = pickle.load(input)\n",
    "    \n",
    "    return clf\n",
    "\n",
    "# writes model to a pickled object file\n",
    "def writeObj(name, obj):\n",
    "    with open(name, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def zipData(X, Y):\n",
    "    return zip(X, Y)\n",
    "\n",
    "def unzipData(X):\n",
    "    x, y = zip(*X)\n",
    "\n",
    "    x = np.array(list(x))\n",
    "    y = np.array([np.where(output == 1)[0][0] for output in list(y)])\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "loading input - output data and explore the dataset\n",
    "\n",
    "'''\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from sklearn import decomposition\n",
    "\n",
    "inputDataPath  = 'data/Proj2FeatVecsSet1.mat'\n",
    "outputDataPath = 'data/Proj2TargetOutputsSet1.mat'\n",
    "\n",
    "inputDataObj  = loadmat(inputDataPath)\n",
    "outputDataObj = loadmat(outputDataPath)\n",
    "\n",
    "inputData  = inputDataObj['Proj2FeatVecsSet1']\n",
    "outputData = outputDataObj['Proj2TargetOutputsSet1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "pretty prints confusion matrix and returns confusion matrix and accuracy score\n",
    "\n",
    "@param   Y                   predicted labels\n",
    "\n",
    "@param   ClassLabels         actual / true labels\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "def MyConfusionMatrix(Y, ClassNames):\n",
    "    ClassLabels = list(np.unique(ClassNames))\n",
    "    \n",
    "    conf_matrix = confusion_matrix(Y, ClassNames)\n",
    "    accuracy = accuracy_score(Y, ClassNames)\n",
    "    \n",
    "    columns = tuple(ClassLabels)\n",
    "    rows = tuple(ClassLabels)\n",
    "    \n",
    "    df = pd.DataFrame(data=conf_matrix, columns=ClassLabels)\n",
    "    \n",
    "    print \"\\nconfusion matrix: \\n\"\n",
    "    print df\n",
    "    \n",
    "    print \"\\n\"\n",
    "    print \"accuracy: \", accuracy\n",
    "    \n",
    "    return conf_matrix, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SVM (Support Vector Machine):\n",
    "\n",
    "performs grid search to compute optimal hyper-parameters\n",
    "uses those hyper-parameters for the estimator, fits it on the training data\n",
    "\n",
    "returns trained model and writes it to file for transfer learning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def SVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train):\n",
    "\n",
    "    hyper_param_grid = [\n",
    "        {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}\n",
    "    ]\n",
    "\n",
    "    estimator = GridSearchCV(SVC(decision_function_shape='ovr'), hyper_param_grid, cv=3, scoring='precision_macro')\n",
    "    \n",
    "    print \"SVM: executing grid search to find optimal hyper-parameters\"\n",
    "    \n",
    "    estimator.fit(X_hyper, Y_hyper)\n",
    "\n",
    "    clf = estimator.best_estimator_\n",
    "    \n",
    "    print \"found best hyperparameters:\"\n",
    "\n",
    "    print estimator.best_params_\n",
    "    print \"training the estimator\"\n",
    "\n",
    "    if train:\n",
    "        clf.fit(X_train, Y_train)\n",
    "        writeObj('svm_model.pkl', clf)\n",
    "        \n",
    "        Y_pred = clf.predict(X_validate)\n",
    "        return Y_pred, clf\n",
    "    \n",
    "    else:\n",
    "        clf = readObj('svm_model.pkl')\n",
    "        print clf.score(X_validate, Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RVM (Relevance Vector Machine):\n",
    "\n",
    "uses PCA to reduce dimensionality as RVM training takes a long time\n",
    "also uses a subset of training data to save time\n",
    "\n",
    "\n",
    "returns trained model and writes it to file for transfer learning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def RVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train):\n",
    "    clf = OneVsRestClassifier(RVC(n_iter=1))\n",
    "    start = time.clock()\n",
    "    \n",
    "    X_train_reduced = reduce_dimensions(X_train)\n",
    "    X_validate_reduced = reduce_dimensions(X_validate)\n",
    "    \n",
    "    if train:\n",
    "        clf.fit(X_train_reduced[:200, :], Y_train[:200])\n",
    "        writeObj('rvm_model.pkl', clf)\n",
    "        \n",
    "        Y_pred = clf.predict(X_validate)\n",
    "        return Y_pred, clf\n",
    "    else:\n",
    "        clf = readObj('rvm_model.pkl')\n",
    "        print clf.score(X_validate_reduced, Y_validate)\n",
    "\n",
    "    print \"training took \", time.clock() - start, \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GPR (Gaussian Process Regressor):\n",
    "\n",
    "uses PCA to reduce dimensionality as training takes a long time\n",
    "also uses a subset of training data to save time\n",
    "\n",
    "returns trained model and writes it to file for transfer learning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import pickle\n",
    "\n",
    "def GPR(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train):\n",
    "    print \"GPR training :\"\n",
    "    \n",
    "    X_train_reduced = reduce_dimensions(X_train)\n",
    "    X_validate_reduced = reduce_dimensions(X_validate)\n",
    "    \n",
    "    if train:\n",
    "        start = time.clock()\n",
    "        kernel_rbf = 1.0 * RBF()\n",
    "        \n",
    "        clf = GaussianProcessClassifier(kernel=kernel_rbf, multi_class='one_vs_rest')\n",
    "        clf.fit(X_train_reduced[:1000, :], Y_train[:1000])\n",
    "\n",
    "        writeObj('gaussian_model.pkl', clf)\n",
    "        print \"training took \", time.clock() - start, \" s\"\n",
    "        \n",
    "        Y_pred = clf.predict(X_validate_reduced)\n",
    "        return Y_pred, clf\n",
    "    else:\n",
    "        clf = readObj('gaussian_model.pkl')\n",
    "\n",
    "        print clf.score(X_validate_reduced[:1000, :], Y_validate[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from skrvm import RVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def MyTrainClassifier(XEstimate, XValidate, Parameters):\n",
    "    \n",
    "    X_train, Y_train = unzipData(XEstimate)\n",
    "\n",
    "    # sampling a small amount of training data for finding optimal hyper-parameters\n",
    "    X_hyper = X_train[:500, :]\n",
    "    Y_hyper = Y_train[:500]\n",
    "\n",
    "    X_validate, Y_validate = unzipData(XValidate)\n",
    "\n",
    "    train = Parameters['training_mode']\n",
    "    \n",
    "    if Parameters['algorithm'] == 'SVM':\n",
    "\n",
    "        Y_predict, model = SVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train)\n",
    "\n",
    "    elif Parameters['algorithm'] == 'RVM':\n",
    "\n",
    "        Y_predict, model = RVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train)\n",
    "\n",
    "    elif Parameters['algorithm'] == 'GPR':\n",
    "\n",
    "        Y_predict, model = GPR(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train)\n",
    "\n",
    "    return Y_predict, {'model' : model, 'algorithm' : Parameters['algorithm']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "takes in XTest ( which is a zipped form of input and output data tuples ) and a trained model\n",
    "evaluates the performance of the model\n",
    "\n",
    "\"\"\"\n",
    "def TestMyClassifier(XTest, EstParameters):\n",
    "    model = EstParameters['model']\n",
    "    \n",
    "    Xactual, Yactual = unzipData(XTest)\n",
    "    Ypred = []\n",
    "    \n",
    "    algorithm = EstParameters['algorithm']\n",
    "    \n",
    "    if algorithm == 'GPR' or algorithm ==  'RVM':\n",
    "        X_actual = reduce_dimensions(X_actual)\n",
    "        \n",
    "    for x in X:\n",
    "        probabilities  = model.predict_proba(X)\n",
    "        max_probabilty = max(p)\n",
    "        \n",
    "        print probabilities\n",
    "        \n",
    "        y = p.index(max_probability)\n",
    "        Ypred.append(y)\n",
    "        \n",
    "    return Ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "performs K-fold cross validation and selects the best model to prevent overfitting\n",
    "returns the array of confusion matrices and estimated parameter models for every fold\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.model_selection import KFold\n",
    "from random import shuffle\n",
    "\n",
    "def MyCrossValidate(XTrain, Nf):\n",
    "    shuffle(XTrain)\n",
    "    kf = KFold(n_splits = Nf)\n",
    "    \n",
    "    j = 1\n",
    "    \n",
    "    EstParameters = []\n",
    "    EstConfMatrices = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(XTrain):\n",
    "        En = [XTrain[i] for i in train_index]\n",
    "        Vn = [XTrain[i] for i in test_index]\n",
    "        \n",
    "        print \"\\nfold {} in progress:\\n\".format(j)\n",
    "        \n",
    "        Y_predicted, EstParameter = MyTrainClassifier(En, Vn, {'algorithm':'GPR', 'training_mode':True})\n",
    "        \n",
    "        _, Y_validate = zip(*Vn)\n",
    "        Y_validate = np.array([np.where(output == 1)[0][0] for output in list(Y_validate)])\n",
    "        \n",
    "        Cn, acc = MyConfusionMatrix(Y_predicted, Y_validate)\n",
    "        \n",
    "        EstConfMatrices.append(Cn)\n",
    "        EstParameters.append(EstParameter)\n",
    "        \n",
    "        accuracies.append(acc)\n",
    "        \n",
    "        j = j + 1\n",
    "    \n",
    "    print \"\"\n",
    "    \n",
    "    best_model_idx = accuracies.index(max(accuracies))\n",
    "    best_model = EstParameters[best_model_idx]['model']\n",
    "    \n",
    "    X, Y = unzipData(XTrain)\n",
    "    \n",
    "    algorithm = EstParameters[best_model_idx]['algorithm']\n",
    "    \n",
    "    if algorithm == 'GPR' or algorithm ==  'RVM':\n",
    "        X = reduce_dimensions(X)\n",
    "        \n",
    "    YTrain = best_model.predict(X)\n",
    "    \n",
    "    print \"overall confusion matrix :\"\n",
    "    \n",
    "    ConfMatrix, acc = MyConfusionMatrix(YTrain, Y)\n",
    "    \n",
    "    return YTrain, EstParameters, EstConfMatrices, ConfMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = zipData(inputData, outputData)\n",
    "\n",
    "MyCrossValidate(data, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
