{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load input - output data and understand the structure\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "inputDataPath  = 'data/Proj2FeatVecsSet1.mat'\n",
    "outputDataPath = 'data/Proj2TargetOutputsSet1.mat'\n",
    "\n",
    "inputDataObj  = loadmat(inputDataPath)\n",
    "outputDataObj = loadmat(outputDataPath)\n",
    "\n",
    "inputData  = inputDataObj['Proj2FeatVecsSet1']\n",
    "outputData = outputDataObj['Proj2TargetOutputsSet1']\n",
    "\n",
    "data = zip(inputData, outputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "computes confusion matrix\n",
    "\n",
    "@param   Y                   predicted labels\n",
    "\n",
    "@param   ClassLabels         actual / true labels  \n",
    "\n",
    "\"\"\" \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def MyConfusionMatrix(Y, ClassNames):\n",
    "    return confusion_matrix(Y, ClassNames)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "training script\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from skrvm import RVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def MyTrainClassifier(XEstimate, XValidate, Parameters):\n",
    "    \n",
    "    X_train, Y_train = zip(*XEstimate)\n",
    "        \n",
    "    X_train = np.array(list(X_train))\n",
    "    Y_train = np.array([np.where(output == 1)[0][0] for output in list(Y_train)])\n",
    "    \n",
    "    # sampling a small amount of training data for finding optimal hyper-parameters\n",
    "    X_hyper = X_train[:1000, :]\n",
    "    Y_hyper = Y_train[:1000]\n",
    "    \n",
    "    X_validate, Y_validate = zip(*XValidate)\n",
    "        \n",
    "    X_validate = list(X_validate)\n",
    "    Y_validate = [np.where(output == 1)[0][0] for output in list(Y_validate)]\n",
    "    \n",
    "    # SVM\n",
    "    # all vs all pair training\n",
    "    if Parameters['algorithm'] == 'SVM':\n",
    "        \n",
    "        SVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate)\n",
    "    \n",
    "    elif Parameters['algorithm'] == 'RVM':\n",
    "        \n",
    "        RVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate)        \n",
    "    \n",
    "    elif Parameters['algorithm'] == 'Gaussian':\n",
    "     \n",
    "        Gaussian(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate):\n",
    "    \n",
    "    hyper_param_grid = [\n",
    "        {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}\n",
    "    ]\n",
    "\n",
    "    estimator = GridSearchCV(SVC(decision_function_shape='ovo'), hyper_param_grid, cv=3, scoring='precision_macro')    \n",
    "    estimator.fit(X_hyper, Y_hyper) \n",
    "    \n",
    "    clf = estimator.best_estimator_\n",
    "    print \"found best estimator, training the estimator\"\n",
    "    \n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    print \"completed training\"\n",
    "    \n",
    "    print clf.score(X_validate, Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate):\n",
    "    clf = RVC(n_iter=1, kernel='linear')\n",
    "\n",
    "    start = time.clock()\n",
    "\n",
    "    clf.fit(X_hyper, Y_hyper)\n",
    "    print time.clock() - start, \"s\"\n",
    "\n",
    "    print clf.score(X_validate, Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "    \n",
    "def Gaussian(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate):\n",
    "    print \"gaussian in progress\"\n",
    "    \n",
    "    kernel = 1.0 * RBF([1.0, 1.0])\n",
    "    clf = GaussianProcessClassifier(kernel, multi_class='one_vs_one')\n",
    "\n",
    "    myclf = OVO('gaussian')\n",
    "    myclf.fit(X_hyper, Y_hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    " K-fold cross validation script\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.model_selection import KFold\n",
    "from random import shuffle\n",
    "\n",
    "def MyCrossValidate(XTrain, Nf):\n",
    "    shuffle(XTrain)\n",
    "    kf = KFold(n_splits = Nf)\n",
    "    \n",
    "    j = 1\n",
    "    \n",
    "    for train_index, test_index in kf.split(XTrain):\n",
    "        En = [XTrain[i] for i in train_index]\n",
    "        Vn = [XTrain[i] for i in test_index]\n",
    "        \n",
    "        print \"fold {} in progress\".format(j)\n",
    "        \n",
    "        MyTrainClassifier(En, Vn, {'algorithm':'Gaussian'})\n",
    "        \n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OVO:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def fact(self, n):\n",
    "        if n == 0:\n",
    "            return 1\n",
    "        \n",
    "        return n*fact(n-1)\n",
    "\n",
    "    def nCr(self, n, r):\n",
    "        return fact(n)/(fact(n-r)*fact(r))\n",
    "    \n",
    "    def getModel(self):\n",
    "        if self.model == 'gaussian':\n",
    "            return GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=1.0))\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        Nclasses     = len(np.unique(Y))\n",
    "        Nclassifiers = self.nCr(Nclasses, 2)\n",
    "        \n",
    "        dataparts = [None]*Nclasses\n",
    "        classifiers = []\n",
    "        \n",
    "        for i in range(Nclasses):\n",
    "            dataparts[i] = np.where(Y == i)[0]\n",
    "            \n",
    "        for i in range(Nclasses):\n",
    "            for j in range(i+1, Nclasses):\n",
    "                \"training classifier: \", i, \" \",j\n",
    "                \n",
    "                xi = X[dataparts[i]]\n",
    "                xj = X[dataparts[j]]\n",
    "                \n",
    "                yi = [0]*len(xi)\n",
    "                yj = [1]*len(xj)\n",
    "                \n",
    "                x = np.vstack([xi, xj])\n",
    "                y = np.hstack([yi, yj])\n",
    "                \n",
    "                clf = self.getModel() \n",
    "                clf.fit(x, y)\n",
    "                \n",
    "                classifiers.append((i, j, clf))\n",
    "        \n",
    "        print classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 in progress\n",
      "gaussian in progress\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "GaussianProcessClassifier requires 2 or more distinct classes. Only class 0 present.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-3720d1702053>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMyCrossValidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-142-7303aff199d3>\u001b[0m in \u001b[0;36mMyCrossValidate\u001b[0;34m(XTrain, Nf)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"fold {} in progress\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mMyTrainClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'algorithm'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Gaussian'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-d9f0399b9c4a>\u001b[0m in \u001b[0;36mMyTrainClassifier\u001b[0;34m(XEstimate, XValidate, Parameters)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'algorithm'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Gaussian'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mGaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_hyper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_hyper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_validate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-141-3c4d8b31d581>\u001b[0m in \u001b[0;36mGaussian\u001b[0;34m(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmyclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOVO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmyclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-144-32a6173f7806>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mclassifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/humble_learner/anaconda2/lib/python2.7/site-packages/sklearn/gaussian_process/gpc.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    594\u001b[0m             raise ValueError(\"GaussianProcessClassifier requires 2 or more \"\n\u001b[1;32m    595\u001b[0m                              \u001b[0;34m\"distinct classes. Only class %s present.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m                              % self.classes_[0])\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"one_vs_rest\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: GaussianProcessClassifier requires 2 or more distinct classes. Only class 0 present."
     ]
    }
   ],
   "source": [
    "MyCrossValidate(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.675773 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Marginal Likelihood (initial): -17.598\n",
      "Log Marginal Likelihood (optimized): -3.875\n",
      "Accuracy: 1.000 (initial) 1.000 (optimized)\n",
      "Log-loss: 0.214 (initial) 0.319 (optimized)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "\n",
    "# Generate data\n",
    "train_size = 50\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "X = rng.uniform(0, 5, 100)[:, np.newaxis]\n",
    "y = np.array(X[:, 0] > 2.5, dtype=int)\n",
    "\n",
    "gp_fix = GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=1.0),\n",
    "                                   optimizer=None)\n",
    "gp_fix.fit(X[:train_size], y[:train_size])\n",
    "\n",
    "gp_opt = GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=1.0))\n",
    "gp_opt.fit(X[:train_size], y[:train_size])\n",
    "\n",
    "print \"Log Marginal Likelihood (initial): %.3f\" % gp_fix.log_marginal_likelihood(gp_fix.kernel_.theta)\n",
    "print \"Log Marginal Likelihood (optimized): %.3f\"% gp_opt.log_marginal_likelihood(gp_opt.kernel_.theta)\n",
    "\n",
    "print \"Accuracy: %.3f (initial) %.3f (optimized)\"% (accuracy_score(y[:train_size], gp_fix.predict(X[:train_size])),\n",
    "         accuracy_score(y[:train_size], gp_opt.predict(X[:train_size])))\n",
    "print \"Log-loss: %.3f (initial) %.3f (optimized)\" % (log_loss(y[:train_size], gp_fix.predict_proba(X[:train_size])[:, 1]),\n",
    "         log_loss(y[:train_size], gp_opt.predict_proba(X[:train_size])[:, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [4 5]\n",
      " [6 7]]\n"
     ]
    }
   ],
   "source": [
    "a = [[1,2], [3,4]]\n",
    "b = [[4,5], [6,7]]\n",
    "\n",
    "print np.vstack([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "yi = [0]*5\n",
    "yj = [1]*10\n",
    "\n",
    "print yi\n",
    "print yj\n",
    "\n",
    "print np.hstack([yi, yj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
