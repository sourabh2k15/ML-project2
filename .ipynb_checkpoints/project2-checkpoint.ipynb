{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "loading input - output data and explore the dataset\n",
    "\n",
    "'''\n",
    "from scipy.io import loadmat\n",
    "from sklearn import decomposition\n",
    "\n",
    "inputDataPath  = 'data/Proj2FeatVecsSet1.mat'\n",
    "outputDataPath = 'data/Proj2TargetOutputsSet1.mat'\n",
    "\n",
    "inputDataObj  = loadmat(inputDataPath)\n",
    "outputDataObj = loadmat(outputDataPath)\n",
    "\n",
    "inputData  = inputDataObj['Proj2FeatVecsSet1']\n",
    "outputData = outputDataObj['Proj2TargetOutputsSet1']\n",
    "\n",
    "\n",
    "data = zip(inputData, outputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "computes confusion matrix\n",
    "\n",
    "@param   Y                   predicted labels\n",
    "\n",
    "@param   ClassLabels         actual / true labels\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "def MyConfusionMatrix(Y, ClassNames):\n",
    "    ClassLabels = list(np.unique(ClassNames))\n",
    "    \n",
    "    conf_matrix = confusion_matrix(Y, ClassNames)\n",
    "    accuracy = accuracy_score(Y, ClassNames)\n",
    "    \n",
    "    columns = tuple(ClassLabels)\n",
    "    rows = tuple(ClassLabels)\n",
    "    \n",
    "    df = pd.DataFrame(data=conf_matrix, columns=ClassLabels)\n",
    "    \n",
    "    print \"\\nconfusion matrix: \\n\"\n",
    "    print df\n",
    "    \n",
    "    return conf_matrix, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train):\n",
    "\n",
    "    hyper_param_grid = [\n",
    "        {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}\n",
    "    ]\n",
    "\n",
    "    estimator = GridSearchCV(SVC(decision_function_shape='ovr'), hyper_param_grid, cv=3, scoring='precision_macro')\n",
    "    \n",
    "    print \"SVM: executing grid search to find optimal hyper-parameters\"\n",
    "    \n",
    "    estimator.fit(X_hyper, Y_hyper)\n",
    "\n",
    "    clf = estimator.best_estimator_\n",
    "    \n",
    "    print \"found best hyperparameters:\"\n",
    "    print estimator.best_params_\n",
    "    print \"training the estimator\"\n",
    "\n",
    "    if train:\n",
    "        clf.fit(X_train, Y_train)\n",
    "        writeObj('svm_model.pkl', clf)\n",
    "        \n",
    "        Y_pred = clf.predict(X_validate)\n",
    "        return Y_pred, clf\n",
    "    \n",
    "    else:\n",
    "        clf = readObj('svm_model.pkl')\n",
    "        print clf.score(X_validate, Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train):\n",
    "    clf = OneVsRestClassifier(RVC(n_iter=1))\n",
    "    start = time.clock()\n",
    "    \n",
    "    X_train_reduced = reduce_dimensions(X_train)\n",
    "    X_validate_reduced = reduce_dimensions(X_validate)\n",
    "    \n",
    "    if train:\n",
    "        clf.fit(X_train_reduced[:5000, :], Y_train[:5000])\n",
    "        writeObj('rvm_model.pkl', clf)\n",
    "    else:\n",
    "        clf = readObj('rvm_model.pkl')\n",
    "        print clf.score(X_validate_reduced, Y_validate)\n",
    "\n",
    "    print time.clock() - start, \"s\"\n",
    "    print clf.predict_proba(X_validate[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import pickle\n",
    "\n",
    "def Gaussian(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train):\n",
    "    print \"gaussian in progress\"\n",
    "\n",
    "    if train:\n",
    "        kernel_rbf = 1.0 * RBF()\n",
    "\n",
    "        clf = GaussianProcessClassifier(kernel=kernel_rbf, multi_class='one_vs_rest')\n",
    "        clf.fit(X_train[:1000, :], Y_train[:1000])\n",
    "\n",
    "        writeObj('gaussian_model', clf)\n",
    "    else:\n",
    "        clf = readObj('gaussian_model')\n",
    "\n",
    "        print clf.score(X_validate[:500, :], Y_validate[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from skrvm import RVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def MyTrainClassifier(XEstimate, XValidate, Parameters):\n",
    "    \n",
    "    X_train, Y_train = zip(*XEstimate)\n",
    "\n",
    "    X_train = np.array(list(X_train))\n",
    "    Y_train = np.array([np.where(output == 1)[0][0] for output in list(Y_train)])\n",
    "\n",
    "    # sampling a small amount of training data for finding optimal hyper-parameters\n",
    "    X_hyper = X_train[:500, :]\n",
    "    Y_hyper = Y_train[:500]\n",
    "\n",
    "    X_validate, Y_validate = zip(*XValidate)\n",
    "\n",
    "    X_validate = np.array(list(X_validate))\n",
    "    Y_validate = np.array([np.where(output == 1)[0][0] for output in list(Y_validate)])\n",
    "    \n",
    "    train = Parameters['training_mode']\n",
    "    \n",
    "    # SVM\n",
    "    if Parameters['algorithm'] == 'SVM':\n",
    "\n",
    "        Y_predict, model = SVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train)\n",
    "\n",
    "    elif Parameters['algorithm'] == 'RVM':\n",
    "\n",
    "        Y_predict, model = RVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train)\n",
    "\n",
    "    elif Parameters['algorithm'] == 'GPR':\n",
    "\n",
    "        Y_predict, model = Gaussian(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train)\n",
    "\n",
    "    return Y_predict, {'model' : model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    " K-fold cross validation script\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.model_selection import KFold\n",
    "from random import shuffle\n",
    "\n",
    "def MyCrossValidate(XTrain, Nf):\n",
    "    shuffle(XTrain)\n",
    "    kf = KFold(n_splits = Nf)\n",
    "    \n",
    "    j = 1\n",
    "    \n",
    "    EstParameters = []\n",
    "    EstConfMatrices = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(XTrain):\n",
    "        En = [XTrain[i] for i in train_index]\n",
    "        Vn = [XTrain[i] for i in test_index]\n",
    "        \n",
    "        print \"\\nfold {} in progress:\\n\".format(j)\n",
    "        \n",
    "        Y_predicted, EstParameter = MyTrainClassifier(En, Vn, {'algorithm':'GPR', 'training_mode':True})\n",
    "        \n",
    "        _, Y_validate = zip(*Vn)\n",
    "        Y_validate = np.array([np.where(output == 1)[0][0] for output in list(Y_validate)])\n",
    "        \n",
    "        Cn, acc = MyConfusionMatrix(Y_predicted, Y_validate)\n",
    "        \n",
    "        EstConfMatrices.append(Cn)\n",
    "        EstParameters.append(EstParameter)\n",
    "        \n",
    "        accuracies.append(acc)\n",
    "        \n",
    "        j = j + 1\n",
    "    \n",
    "    print \"\"\n",
    "    \n",
    "    best_model_idx = accuracies.index(max(accuracies))\n",
    "    best_model = EstParameters[best_model_idx]['model']\n",
    "    \n",
    "    X, Y = zip(*XTrain)\n",
    "    \n",
    "    X = np.array(list(X))\n",
    "    Y = np.array([np.where(output == 1)[0][0] for output in list(Y)])\n",
    "    \n",
    "    YTrain = best_model.predict(X)\n",
    "    \n",
    "    print \"overall confusion matrix :\"\n",
    "    \n",
    "    ConfMatrix, acc = MyConfusionMatrix(YTrain, Y)\n",
    "    \n",
    "    return YTrain, EstParameters, EstConfMatrices, ConfMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fold 1 in progress:\n",
      "\n",
      "SVM: executing grid search to find optimal hyper-parameters\n",
      "found best hyperparameters:\n",
      "{'kernel': 'linear', 'C': 100}\n",
      "training the estimator\n",
      "\n",
      "confusion matrix: \n",
      "\n",
      "     0     1    2    3    4\n",
      "0  986     1    7    4    2\n",
      "1    1  1007    0   23    0\n",
      "2    2     1  989    3    4\n",
      "3    0    17    2  965    5\n",
      "4    0     0    7   13  961\n",
      "\n",
      "fold 2 in progress:\n",
      "\n",
      "SVM: executing grid search to find optimal hyper-parameters\n",
      "found best hyperparameters:\n",
      "{'kernel': 'linear', 'C': 10}\n",
      "training the estimator\n",
      "\n",
      "confusion matrix: \n",
      "\n",
      "     0    1     2    3    4\n",
      "0  965    4     6    2    4\n",
      "1    2  981     1   27    0\n",
      "2    3    2  1004    2    9\n",
      "3    0   19     1  976    7\n",
      "4    0    0    12    8  965\n",
      "\n",
      "fold 3 in progress:\n",
      "\n",
      "SVM: executing grid search to find optimal hyper-parameters\n",
      "found best hyperparameters:\n",
      "{'kernel': 'linear', 'C': 10}\n",
      "training the estimator\n",
      "\n",
      "confusion matrix: \n",
      "\n",
      "     0    1    2    3     4\n",
      "0  988    0    7    5     4\n",
      "1    4  948    1   12     0\n",
      "2    5    0  983    1     6\n",
      "3    0   30    1  981     3\n",
      "4    1    0    4    9  1007\n",
      "\n",
      "fold 4 in progress:\n",
      "\n",
      "SVM: executing grid search to find optimal hyper-parameters\n",
      "found best hyperparameters:\n",
      "{'kernel': 'linear', 'C': 10}\n",
      "training the estimator\n",
      "\n",
      "confusion matrix: \n",
      "\n",
      "      0    1    2    3     4\n",
      "0  1021    3    7    1     3\n",
      "1     2  918    1   19     1\n",
      "2     4    3  975    3     4\n",
      "3     0   15    1  977     5\n",
      "4     1    1    7    6  1022\n",
      "\n",
      "fold 5 in progress:\n",
      "\n",
      "SVM: executing grid search to find optimal hyper-parameters\n",
      "found best hyperparameters:\n",
      "{'kernel': 'linear', 'C': 10}\n",
      "training the estimator\n",
      "\n",
      "confusion matrix: \n",
      "\n",
      "      0     1    2    3    4\n",
      "0  1007     3    4    1    2\n",
      "1     6  1019    2   17    1\n",
      "2     2     7  969    3    5\n",
      "3     0    21    1  939   10\n",
      "4     0     0    8    3  970\n",
      "\n",
      "overall confusion matrix :\n",
      "\n",
      "confusion matrix: \n",
      "\n",
      "      0     1     2     3     4\n",
      "0  4969    12    29    12    14\n",
      "1    12  4883     4    96     1\n",
      "2    15    11  4923    14    28\n",
      "3     0    93     7  4844    27\n",
      "4     4     1    37    34  4930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3, 0, 3, ..., 2, 2, 2]),\n",
       " [{'model': SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False)},\n",
       "  {'model': SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False)},\n",
       "  {'model': SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False)},\n",
       "  {'model': SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False)},\n",
       "  {'model': SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False)}],\n",
       " [array([[ 986,    1,    7,    4,    2],\n",
       "         [   1, 1007,    0,   23,    0],\n",
       "         [   2,    1,  989,    3,    4],\n",
       "         [   0,   17,    2,  965,    5],\n",
       "         [   0,    0,    7,   13,  961]]),\n",
       "  array([[ 965,    4,    6,    2,    4],\n",
       "         [   2,  981,    1,   27,    0],\n",
       "         [   3,    2, 1004,    2,    9],\n",
       "         [   0,   19,    1,  976,    7],\n",
       "         [   0,    0,   12,    8,  965]]),\n",
       "  array([[ 988,    0,    7,    5,    4],\n",
       "         [   4,  948,    1,   12,    0],\n",
       "         [   5,    0,  983,    1,    6],\n",
       "         [   0,   30,    1,  981,    3],\n",
       "         [   1,    0,    4,    9, 1007]]),\n",
       "  array([[1021,    3,    7,    1,    3],\n",
       "         [   2,  918,    1,   19,    1],\n",
       "         [   4,    3,  975,    3,    4],\n",
       "         [   0,   15,    1,  977,    5],\n",
       "         [   1,    1,    7,    6, 1022]]),\n",
       "  array([[1007,    3,    4,    1,    2],\n",
       "         [   6, 1019,    2,   17,    1],\n",
       "         [   2,    7,  969,    3,    5],\n",
       "         [   0,   21,    1,  939,   10],\n",
       "         [   0,    0,    8,    3,  970]])],\n",
       " array([[4969,   12,   29,   12,   14],\n",
       "        [  12, 4883,    4,   96,    1],\n",
       "        [  15,   11, 4923,   14,   28],\n",
       "        [   0,   93,    7, 4844,   27],\n",
       "        [   4,    1,   37,   34, 4930]]))"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyCrossValidate(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeObj(name, obj):\n",
    "    with open(name, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readObj(name):\n",
    "    with open(name, 'rb') as input:\n",
    "        clf = pickle.load(input)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_dimensions(data):\n",
    "    pca = decomposition.PCA(n_components = 7)\n",
    "    \n",
    "    X = pca.fit_transform(data)\n",
    "    return X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
