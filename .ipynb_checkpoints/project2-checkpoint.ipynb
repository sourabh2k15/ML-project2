{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Utility methods\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# do PCA to reduce dimensionality, required for RVM and GPR\n",
    "def reduce_dimensions(data):\n",
    "    pca = decomposition.PCA(n_components = 7)\n",
    "    \n",
    "    X = pca.fit_transform(data)\n",
    "    return X\n",
    "\n",
    "# reads model from pickled object file\n",
    "def readObj(name):\n",
    "    with open(name, 'rb') as input:\n",
    "        clf = pickle.load(input)\n",
    "    \n",
    "    return clf\n",
    "\n",
    "# writes model to a pickled object file\n",
    "def writeObj(name, obj):\n",
    "    with open(name, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def zipData(X, Y):\n",
    "    return zip(X, Y)\n",
    "\n",
    "def unzipData(X):\n",
    "    x, y = zip(*X)\n",
    "\n",
    "    x = np.array(list(x))\n",
    "    y = np.array([np.where(output == 1)[0][0] for output in list(y)])\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "loading input - output data and explore the dataset\n",
    "\n",
    "'''\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from sklearn import decomposition\n",
    "\n",
    "inputDataPath  = 'data/Proj2FeatVecsSet1.mat'\n",
    "outputDataPath = 'data/Proj2TargetOutputsSet1.mat'\n",
    "\n",
    "inputDataObj  = loadmat(inputDataPath)\n",
    "outputDataObj = loadmat(outputDataPath)\n",
    "\n",
    "inputData  = inputDataObj['Proj2FeatVecsSet1']\n",
    "outputData = outputDataObj['Proj2TargetOutputsSet1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "pretty prints confusion matrix and returns confusion matrix and accuracy score\n",
    "\n",
    "@param   Y                   predicted labels\n",
    "\n",
    "@param   ClassLabels         actual / true labels\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "def MyConfusionMatrix(Y, ClassNames):\n",
    "    ClassLabels = list(np.unique(ClassNames))\n",
    "    \n",
    "    conf_matrix = confusion_matrix(Y, ClassNames)\n",
    "    accuracy = accuracy_score(Y, ClassNames)\n",
    "    \n",
    "    columns = tuple(ClassLabels)\n",
    "    rows = tuple(ClassLabels)\n",
    "    \n",
    "    df = pd.DataFrame(data=conf_matrix, columns=ClassLabels)\n",
    "    \n",
    "    print \"\\nconfusion matrix: \\n\"\n",
    "    print df\n",
    "    \n",
    "    print \"\\n\"\n",
    "    print \"accuracy: \", accuracy\n",
    "    \n",
    "    return conf_matrix, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SVM (Support Vector Machine):\n",
    "\n",
    "performs grid search to compute optimal hyper-parameters\n",
    "uses those hyper-parameters for the estimator, fits it on the training data\n",
    "\n",
    "returns trained model and writes it to file for transfer learning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def SVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train):\n",
    "\n",
    "    hyper_param_grid = [\n",
    "        {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}\n",
    "    ]\n",
    "\n",
    "    estimator = GridSearchCV(SVC(decision_function_shape='ovr'), hyper_param_grid, cv=3, scoring='precision_macro')\n",
    "    \n",
    "    print \"SVM: executing grid search to find optimal hyper-parameters\"\n",
    "    \n",
    "    estimator.fit(X_hyper, Y_hyper)\n",
    "\n",
    "    clf = estimator.best_estimator_\n",
    "    \n",
    "    print \"found best hyperparameters:\"\n",
    "\n",
    "    print estimator.best_params_\n",
    "    print \"training the estimator\"\n",
    "\n",
    "    if train:\n",
    "        clf.fit(X_train, Y_train)\n",
    "        writeObj('svm_model.pkl', clf)\n",
    "        \n",
    "        Y_pred = clf.predict(X_validate)\n",
    "        return Y_pred, clf\n",
    "    \n",
    "    else:\n",
    "        clf = readObj('svm_model.pkl')\n",
    "        print clf.score(X_validate, Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RVM (Relevance Vector Machine):\n",
    "\n",
    "uses PCA to reduce dimensionality as RVM training takes a long time\n",
    "also uses a subset of training data to save time\n",
    "\n",
    "\n",
    "returns trained model and writes it to file for transfer learning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def RVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train):\n",
    "    clf = OneVsRestClassifier(RVC(n_iter=1))\n",
    "    start = time.clock()\n",
    "    \n",
    "    X_train_reduced = reduce_dimensions(X_train)\n",
    "    X_validate_reduced = reduce_dimensions(X_validate)\n",
    "    \n",
    "    if train:\n",
    "        clf.fit(X_train_reduced[:200, :], Y_train[:200])\n",
    "        writeObj('rvm_model.pkl', clf)\n",
    "        \n",
    "        Y_pred = clf.predict(X_validate)\n",
    "        return Y_pred, clf\n",
    "    else:\n",
    "        clf = readObj('rvm_model.pkl')\n",
    "        print clf.score(X_validate_reduced, Y_validate)\n",
    "\n",
    "    print \"training took \", time.clock() - start, \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GPR (Gaussian Process Regressor):\n",
    "\n",
    "uses PCA to reduce dimensionality as training takes a long time\n",
    "also uses a subset of training data to save time\n",
    "\n",
    "returns trained model and writes it to file for transfer learning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import pickle\n",
    "\n",
    "def GPR(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train):\n",
    "    print \"GPR training :\"\n",
    "    \n",
    "    X_train_reduced = reduce_dimensions(X_train)\n",
    "    X_validate_reduced = reduce_dimensions(X_validate)\n",
    "    \n",
    "    if train:\n",
    "        start = time.clock()\n",
    "        kernel_rbf = 1.0 * RBF()\n",
    "        \n",
    "        clf = GaussianProcessClassifier(kernel=kernel_rbf, multi_class='one_vs_rest')\n",
    "        clf.fit(X_train_reduced[:500, :], Y_train[:500])\n",
    "\n",
    "        writeObj('gaussian_model.pkl', clf)\n",
    "        print \"training took \", time.clock() - start, \" s\"\n",
    "        \n",
    "        Y_pred = clf.predict(X_validate_reduced)\n",
    "        return Y_pred, clf\n",
    "    else:\n",
    "        clf = readObj('gaussian_model.pkl')\n",
    "\n",
    "        print clf.score(X_validate_reduced[:500, :], Y_validate[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from skrvm import RVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def MyTrainClassifier(XEstimate, XValidate, Parameters):\n",
    "    \n",
    "    X_train, Y_train = unzipData(XEstimate)\n",
    "\n",
    "    # sampling a small amount of training data for finding optimal hyper-parameters\n",
    "    X_hyper = X_train[:500, :]\n",
    "    Y_hyper = Y_train[:500]\n",
    "\n",
    "    X_validate, Y_validate = unzipData(XValidate)\n",
    "\n",
    "    train = Parameters['training_mode']\n",
    "    \n",
    "    if Parameters['algorithm'] == 'SVM':\n",
    "\n",
    "        Y_predict, model = SVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train)\n",
    "\n",
    "    elif Parameters['algorithm'] == 'RVM':\n",
    "\n",
    "        Y_predict, model = RVM(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train)\n",
    "\n",
    "    elif Parameters['algorithm'] == 'GPR':\n",
    "\n",
    "        Y_predict, model = GPR(X_hyper, Y_hyper, X_train, Y_train, X_validate, Y_validate, train)\n",
    "\n",
    "    return Y_predict, {'model' : model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "takes in XTest ( which is a zipped form of input and output data tuples ) and a trained model\n",
    "evaluates the performance of the model\n",
    "\n",
    "\"\"\"\n",
    "def TestMyClassifier(XTest, EstParameters):\n",
    "    model = EstParameters['model']\n",
    "    \n",
    "    Xactual, Yactual = unzipData(XTest)\n",
    "    Ypred = []\n",
    "    \n",
    "    for x in X:\n",
    "        probabilities  = model.predict_proba(X)\n",
    "        max_probabilty = max(p)\n",
    "        \n",
    "        print probabilities\n",
    "        \n",
    "        y = p.index(max_probability)\n",
    "        Ypred.append(y)\n",
    "        \n",
    "    return Ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "performs K-fold cross validation and selects the best model to prevent overfitting\n",
    "returns the array of confusion matrices and estimated parameter models for every fold\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.model_selection import KFold\n",
    "from random import shuffle\n",
    "\n",
    "def MyCrossValidate(XTrain, Nf):\n",
    "    shuffle(XTrain)\n",
    "    kf = KFold(n_splits = Nf)\n",
    "    \n",
    "    j = 1\n",
    "    \n",
    "    EstParameters = []\n",
    "    EstConfMatrices = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(XTrain):\n",
    "        En = [XTrain[i] for i in train_index]\n",
    "        Vn = [XTrain[i] for i in test_index]\n",
    "        \n",
    "        print \"\\nfold {} in progress:\\n\".format(j)\n",
    "        \n",
    "        Y_predicted, EstParameter = MyTrainClassifier(En, Vn, {'algorithm':'SVM', 'training_mode':True})\n",
    "        \n",
    "        _, Y_validate = zip(*Vn)\n",
    "        Y_validate = np.array([np.where(output == 1)[0][0] for output in list(Y_validate)])\n",
    "        \n",
    "        Cn, acc = MyConfusionMatrix(Y_predicted, Y_validate)\n",
    "        \n",
    "        EstConfMatrices.append(Cn)\n",
    "        EstParameters.append(EstParameter)\n",
    "        \n",
    "        accuracies.append(acc)\n",
    "        \n",
    "        j = j + 1\n",
    "    \n",
    "    print \"\"\n",
    "    \n",
    "    best_model_idx = accuracies.index(max(accuracies))\n",
    "    best_model = EstParameters[best_model_idx]['model']\n",
    "    \n",
    "    X, Y = unzipData(XTrain)\n",
    "    \n",
    "    YTrain = best_model.predict(X)\n",
    "    \n",
    "    print \"overall confusion matrix :\"\n",
    "    \n",
    "    ConfMatrix, acc = MyConfusionMatrix(YTrain, Y)\n",
    "    \n",
    "    return YTrain, EstParameters, EstConfMatrices, ConfMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fold 1 in progress:\n",
      "\n",
      "SVM: executing grid search to find optimal hyper-parameters\n",
      "found best hyperparameters:\n",
      "{'kernel': 'rbf', 'C': 1000, 'gamma': 0.001}\n",
      "training the estimator\n",
      "\n",
      "confusion matrix: \n",
      "\n",
      "     0    1    2    3     4\n",
      "0  939    7    7    3     4\n",
      "1    8  920    0   23     0\n",
      "2    4    1  991    6     8\n",
      "3    0   28    1  987     9\n",
      "4    0    0    8   12  1034\n",
      "\n",
      "fold 2 in progress:\n",
      "\n",
      "SVM: executing grid search to find optimal hyper-parameters\n",
      "found best hyperparameters:\n",
      "{'kernel': 'linear', 'C': 100}\n",
      "training the estimator\n",
      "\n",
      "confusion matrix: \n",
      "\n",
      "      0     1    2    3     4\n",
      "0  1048     2    1    3     2\n",
      "1     2  1010    3   17     0\n",
      "2     2     1  923    1     7\n",
      "3     0    17    4  939     0\n",
      "4     0     0    4   13  1001\n",
      "\n",
      "fold 3 in progress:\n",
      "\n",
      "SVM: executing grid search to find optimal hyper-parameters\n",
      "found best hyperparameters:\n",
      "{'kernel': 'linear', 'C': 100}\n",
      "training the estimator\n",
      "\n",
      "confusion matrix: \n",
      "\n",
      "      0     1    2    3    4\n",
      "0  1004     3    5    2    4\n",
      "1     2  1002    2   13    1\n",
      "2     6     2  978    1    7\n",
      "3     0    19    1  995    7\n",
      "4     1     1    7    8  929\n",
      "\n",
      "fold 4 in progress:\n",
      "\n",
      "SVM: executing grid search to find optimal hyper-parameters\n",
      "found best hyperparameters:\n",
      "{'kernel': 'linear', 'C': 100}\n",
      "training the estimator\n",
      "\n",
      "confusion matrix: \n",
      "\n",
      "     0    1     2    3    4\n",
      "0  998    0    10    2    1\n",
      "1    1  986     3   18    1\n",
      "2    0    3  1010    4    4\n",
      "3    0   20     1  971    3\n",
      "4    1    0     7    5  951\n",
      "\n",
      "fold 5 in progress:\n",
      "\n",
      "SVM: executing grid search to find optimal hyper-parameters\n",
      "found best hyperparameters:\n",
      "{'kernel': 'linear', 'C': 100}\n",
      "training the estimator\n",
      "\n",
      "confusion matrix: \n",
      "\n",
      "     0    1     2    3     4\n",
      "0  976    3     8    1     0\n",
      "1    4  957     1   18     0\n",
      "2    2    1  1016    3     3\n",
      "3    0   17     0  950     5\n",
      "4    2    0     9    5  1019\n",
      "\n",
      "overall confusion matrix :\n",
      "\n",
      "confusion matrix: \n",
      "\n",
      "      0     1     2     3     4\n",
      "0  4979     8    19    10     8\n",
      "1     8  4895     5    84     1\n",
      "2    12     6  4948     5    18\n",
      "3     0    90     7  4866    15\n",
      "4     1     1    21    35  4958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3, 1, 0, ..., 0, 2, 1]),\n",
       " [{'model': SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False)},\n",
       "  {'model': SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False)},\n",
       "  {'model': SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False)},\n",
       "  {'model': SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False)},\n",
       "  {'model': SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False)}],\n",
       " [array([[ 939,    7,    7,    3,    4],\n",
       "         [   8,  920,    0,   23,    0],\n",
       "         [   4,    1,  991,    6,    8],\n",
       "         [   0,   28,    1,  987,    9],\n",
       "         [   0,    0,    8,   12, 1034]]),\n",
       "  array([[1048,    2,    1,    3,    2],\n",
       "         [   2, 1010,    3,   17,    0],\n",
       "         [   2,    1,  923,    1,    7],\n",
       "         [   0,   17,    4,  939,    0],\n",
       "         [   0,    0,    4,   13, 1001]]),\n",
       "  array([[1004,    3,    5,    2,    4],\n",
       "         [   2, 1002,    2,   13,    1],\n",
       "         [   6,    2,  978,    1,    7],\n",
       "         [   0,   19,    1,  995,    7],\n",
       "         [   1,    1,    7,    8,  929]]),\n",
       "  array([[ 998,    0,   10,    2,    1],\n",
       "         [   1,  986,    3,   18,    1],\n",
       "         [   0,    3, 1010,    4,    4],\n",
       "         [   0,   20,    1,  971,    3],\n",
       "         [   1,    0,    7,    5,  951]]),\n",
       "  array([[ 976,    3,    8,    1,    0],\n",
       "         [   4,  957,    1,   18,    0],\n",
       "         [   2,    1, 1016,    3,    3],\n",
       "         [   0,   17,    0,  950,    5],\n",
       "         [   2,    0,    9,    5, 1019]])],\n",
       " array([[4979,    8,   19,   10,    8],\n",
       "        [   8, 4895,    5,   84,    1],\n",
       "        [  12,    6, 4948,    5,   18],\n",
       "        [   0,   90,    7, 4866,   15],\n",
       "        [   1,    1,   21,   35, 4958]]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = zipData(inputData, outputData)\n",
    "\n",
    "MyCrossValidate(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
